{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "CNN_HM3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_PB5MFldxch"
      },
      "source": [
        "# Home 3: Build a CNN for image recognition.\n",
        "\n",
        "### Name: [Hai Huang]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwceFa2Jdxcj"
      },
      "source": [
        "## 0. You will do the following:\n",
        "\n",
        "1. Read, complete, and run the code.\n",
        "\n",
        "2. **Make substantial improvements** to maximize the accurcy.\n",
        "    \n",
        "3. Convert the .IPYNB file to .HTML file.\n",
        "\n",
        "    * The HTML file must contain the code and the output after execution.\n",
        "    \n",
        "    \n",
        "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo.\n",
        "\n",
        "4. Submit the link to this .HTML file to Canvas.\n",
        "\n",
        "    * Example: https://github.com/wangshusen/CS583-2019F/blob/master/homework/HM3/HM3.html\n",
        "\n",
        "\n",
        "## Requirements:\n",
        "\n",
        "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
        "\n",
        "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
        "\n",
        "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
        "\n",
        "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
        "\n",
        "\n",
        "## Google Colab\n",
        "\n",
        "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
        "\n",
        "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
        "\n",
        "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
        "\n",
        "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV3kkaHmdxck"
      },
      "source": [
        "## 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iCLIR6Sdxck"
      },
      "source": [
        "### 1.1. Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjTA794wdxck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "259db308-630b-4217-b008-fc52f52cc165"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt4WZ93gdxcl"
      },
      "source": [
        "### 1.2. One-hot encode the labels\n",
        "\n",
        "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
        "\n",
        "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
        "\n",
        "2. Apply the function to ```y_train``` and ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT5Np1SFdxcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49760651-a601-4f5d-c4d5-f21b700b60de"
      },
      "source": [
        "def to_one_hot(y, num_class=10):\n",
        "    targets = np.array(y).reshape(-1)\n",
        "    return np.eye(num_class)[targets]\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJx_lSHKdxcm"
      },
      "source": [
        "#### Remark: the outputs should be\n",
        "* Shape of y_train_vec: (50000, 10)\n",
        "* Shape of y_test_vec: (10000, 10)\n",
        "* [6]\n",
        "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFrUtPXWdxcm"
      },
      "source": [
        "### 1.3. Randomly partition the training set to training and validation sets\n",
        "\n",
        "Randomly partition the 50K training samples to 2 sets:\n",
        "* a training set containing 40K samples\n",
        "* a validation set containing 10K samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wccVfVSddxcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "170b7826-eb1e-4bc5-f997-073b02c0d941"
      },
      "source": [
        "rand_indices = np.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRzMVXk1dxcn"
      },
      "source": [
        "## 2. Build a CNN and tune its hyper-parameters\n",
        "\n",
        "1. Build a convolutional neural network model\n",
        "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
        "    * Do NOT use test data for hyper-parameter tuning!!!\n",
        "3. Try to achieve a validation accuracy as high as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBfDxrlMdxcn"
      },
      "source": [
        "### Remark: \n",
        "\n",
        "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
        "* Add more layers.\n",
        "* Use regularizations, e.g., dropout.\n",
        "* Use batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEV3pCDgdxcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e8f27e-ec0c-43d5-e278-514dd0d387b8"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3),kernel_regularizer=regularizers.l2(l=0.1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), activation='relu', kernel_regularizer = regularizers.l2(l=0.1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.20))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(l=0.1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), activation='relu', kernel_regularizer = regularizers.l2(l=0.1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.30))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 15, 15, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 13, 13, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 13, 13, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 196,618\n",
            "Trainable params: 196,298\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN-I7OAsdxcn"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 0.0001 # to be tuned!\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDs7SMH4dxco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c32a70-b256-45b6-ef6b-9898b1e86ebd"
      },
      "source": [
        "history = model.fit(x_tr, y_tr, batch_size=32, epochs=10, validation_data=(x_val, y_val))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 41s 6ms/step - loss: 12.3736 - acc: 0.2600 - val_loss: 6.2678 - val_acc: 0.4494\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 5.4006 - acc: 0.4613 - val_loss: 3.5156 - val_acc: 0.5223\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 3.1874 - acc: 0.5356 - val_loss: 2.4993 - val_acc: 0.5655\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 2.2834 - acc: 0.5955 - val_loss: 1.8768 - val_acc: 0.6349\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.8144 - acc: 0.6356 - val_loss: 1.5610 - val_acc: 0.6756\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.5235 - acc: 0.6699 - val_loss: 1.3895 - val_acc: 0.6843\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3384 - acc: 0.6987 - val_loss: 1.2301 - val_acc: 0.7117\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.2149 - acc: 0.7123 - val_loss: 1.1879 - val_acc: 0.7090\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1151 - acc: 0.7311 - val_loss: 1.1871 - val_acc: 0.6991\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0511 - acc: 0.7371 - val_loss: 1.0500 - val_acc: 0.7337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu9K911Vdxco",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "b520f1ef-de19-4ab0-e6de-0e1f2c2f657c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXiU5dn38e9JlCWAyupCIIkWpMoWSHHBIoooii9UWy1IK+hTKbZopbVKq1WL8tQqdWvRPtG61VBcaim2uACCWtwIigsgEhYl1NYIishOON8/rglMwgQmkMk9JL/Pccwxc1/3MmcGnXOu+9rM3REREamsQdQBiIhIelKCEBGRhJQgREQkISUIERFJSAlCREQSOijqAGpK69atPScnJ+owREQOKPPnz//M3dsk2ldnEkROTg5FRUVRhyEickAxs4+q2pfSW0xmNtDMlphZsZmNS7D/TjNbEHt8aGZfxO0ri9s3LZVxiojI7lJWgzCzDGASMAAoAeaZ2TR3X1R+jLuPjTv+CiAv7hKb3L1HquITEZE9S2UNojdQ7O7L3X0rMAUYsofjhwF/SWE8IiJSDalsg2gHrIrbLgFOSHSgmWUDucCLccWNzawI2A7c6u5TE5w3ChgF0KFDh92uu23bNkpKSti8efO+/g2SYo0bNyYrK4uDDz446lBEpJJ0aaQeCjzl7mVxZdnuvtrMjgZeNLP33H1Z/EnuXgAUAOTn5+82qVRJSQnNmzcnJycHM0tl/LIP3J01a9ZQUlJCbm5u1OGISCWpvMW0Gmgft50VK0tkKJVuL7n76tjzcmAOFdsnkrJ582ZatWql5JCmzIxWrVqphieyjwoLIScHGjQIz4WFNXv9VCaIeUBHM8s1s4aEJLBbbyQz6wy0AF6LK2thZo1ir1sDfYBFlc9NhpJDetO/j8i+KSyEUaPgo4/APTyPGlWzSSJlCcLdtwNjgOeBxcAT7r7QzMab2eC4Q4cCU7zivONfB4rM7B1gNqENYp8ShIhIXXTddbBxY8WyjRtDeU1JaRuEu08Hplcqu6HS9k0JznsV6JrK2GrDmjVr6N+/PwD/+c9/yMjIoE2bMGDxzTffpGHDhlWeW1RUxKOPPso999yzx/c4+eSTefXVV2suaBE5IHz8cfXK94XmYopT0/fzWrVqxYIFC1iwYAGjR49m7NixO7cbNmzI9u3bqzw3Pz9/r8kBUHIQqad2ddx0mvNlgvL9pwQRUxv38wBGjhzJ6NGjOeGEE7jmmmt48803Oemkk8jLy+Pkk09myZIlAMyZM4dzzz0XgJtuuolLL72Ufv36cfTRR1dIHM2aNdt5fL9+/fjOd75D586dGT58OOV37aZPn07nzp3p1asXV1555c7rxlu5ciXf/OY36dmzJz179qyQeH7729/StWtXunfvzrhxYUB8cXExZ5xxBt27d6dnz54sW7Zst2uK1FWpbhxOxoRbnHMbzeBfnMITXAhAZiZMmFCDb+LudeLRq1cvr2zRokW7lVUlO9s9pIaKj+zspC+xRzfeeKPffvvtPmLECB80aJBv377d3d3XrVvn27Ztc3f3GTNm+Pnnn+/u7rNnz/ZBgwbtPPekk07yzZs3e2lpqbds2dK3bt3q7u5Nmzbdefwhhxziq1at8rKyMj/xxBP9lVde8U2bNnlWVpYvX77c3d2HDh2687rxNmzY4Js2bXJ39w8//NDLP8/p06f7SSed5Bs2bHB39zVr1ri7e+/evf3pp592d/dNmzbt3L8vqvPvJBK1xx5zz8ys+D2RmRnKa8WOHe4vvOB+8snu4Kszsvxy7vXsDjv2KQagyKv4Xk2XcRCRq437eeUuuOACMjIyAFi3bh0jRoxg6dKlmBnbtm1LeM6gQYNo1KgRjRo1om3btvz3v/8lKyurwjG9e/feWdajRw9WrlxJs2bNOProo3eOMxg2bBgFBQW7XX/btm2MGTOGBQsWkJGRwYcffgjAzJkzueSSS8jMzASgZcuWrF+/ntWrV3PeeecBYbCbSH2xp8bh4cNT+MbuMGsW3HQTzJ0LWVlw770cdeml3NuoUUreUreYYqq6b1eT9/PKNW3adOfrX/3qV5x22mm8//77PPPMM1WOCWgU9x9ARkZGwvaLZI6pyp133snhhx/OO++8Q1FREVu3bk36XJH6pDZ/TAK7EkPfvjBgAKxcCZMmQXExXH45pCg5gBLEThMmhPt38Wr8fl4C69ato127dgA8/PDDNX79Y489luXLl7Ny5UoAHn/88SrjOPLII2nQoAF//vOfKSsLg9oHDBjAQw89xMbYT6a1a9fSvHlzsrKymDo1zH6yZcuWnftF6rpa+zHpDi++CKeeCmecAStWwB/+EBLDj36U0sRQTgkiZvhwKCiA7GwwC88FBSmuMgLXXHMNv/jFL8jLy6vWL/5kNWnShHvvvZeBAwfSq1cvmjdvzqGHHrrbcT/60Y945JFH6N69Ox988MHOWs7AgQMZPHgw+fn59OjRg4kTJwLw5z//mXvuuYdu3bpx8skn85///KfGYxdJRyn/MRmfGPr3h2XL4Pe/D4nhxz+G2rylW1XjxIH22N9G6rps/fr17u6+Y8cOv/zyy/2OO+6IOKKK9O8kB5rHHgsdWMzCc401UL/4onvfvqHl+6ij3H//e/dY55FUYQ+N1KpB1AP3338/PXr04Pjjj2fdunX88Ic/jDokkQPa8OGhKWDHjvC833ca5syBfv3g9NNh6VK4555QcxgzpnZrDJWoF1M9MHbsWMaOHbv3A0Wkdr30UuiVNGcOHHkk3H13GICVJj0DVYMQkQNGOgxQqxEvvwynnRZqDR98EBLDsmVw5ZVpkxxANQgRqY6PP4aystAqW/6IjelJtfLZDso7zJXPdgCp70xSY15+OdQYZs+GI46Au+4Kf0STJlFHlpAShIjs2fr18Je/hG598+fvvr9hw4oJIxWPxo257jqLZoBaTXjllZAYXnwRDj8c7rwTfvjDtE0M5ZQgRGR37lBUBPffD5Mnw4YN0LUr/O530KpV+GbesCE87+nx+ee7l23aVP14zFjoTdhIJhvJ5EsOYTlHs5SOLPvoazCrI3TsGEYXN0ijO+f/+ldIDLNmhcRwxx0hMVTuJ5umlCBS6LTTTmPcuHGcddZZO8vuuusulixZwn333ZfwnH79+jFx4kTy8/M555xzmDx5MocddliFY2666SaaNWvG1VdfXeV7T506lU6dOnHccccBcMMNN9C3b1/OOOOMGvjLpM5aty4khIICWLAgfJENHQqXXQYnnBAGCe2vHTtg8+a9J5dKj8K7N7L9y5AiWvA5x7CMM3mBJmyG8v+sGzWCY44JyaL88bWvhed27WovecydCzfeeMAmhnIpTRBmNhC4G8gAHnD3WyvtvxM4LbaZCbR198Ni+0YA18f23eLuj6Qy1lQYNmwYU6ZMqZAgpkyZwm233ZbU+dOnT9/7QVWYOnUq55577s4EMX78+H2+ltRx7vD666G28Pjj4Qu5Rw+491646CJIMLByvzRosOvWUTU0PbZiGwRA0yY7+POtqzmvy9LQPXTp0jCgbOlSeO452LJl18GNG++ePMoTyFFH1UzymDs31BhmzoS2bUONa/ToAy4x7FTVAIn9fRCSwjLgaKAh8A5w3B6OvwJ4MPa6JbA89twi9rrFnt4vHQfKrVmzxtu0aeNbtmxxd/cVK1Z4+/btfceOHT569Gjv1auXH3fccX7DDTfsPOfUU0/1efPmubt7dna2l5aWurv7Lbfc4h07dvQ+ffr40KFD/fbbb3d394KCAs/Pz/du3br5+eef7xs2bPC5c+d6ixYtPCcnx7t37+7FxcU+YsQIf/LJJ93dfebMmd6jRw/v0qWLX3LJJb558+ad73fDDTd4Xl6ed+nSxRcvXrzb37RixQo/5ZRTPC8vz/Py8nzu3Lk79916663epUsX79atm1977bXu7r506VLv37+/d+vWzfPy8ry4uHi3a0b971RvrV3rfs897l26hIFZzZq5X3aZ+7x5YcbQNFStAWplZe4ffeQ+c6b7ffe5/+xn7oMHu3/96+4NG1acjrVJE/euXd3PP9/9mmvc77/ffc4c95KS5D6LuXPdBwwI12rb1n3iRPevvqqhvzq1iGg2195AsbsvBzCzKcAQql5behhwY+z1WcAMd18bO3cGMBD4yz5Hc9VVocpck3r0CL0QqtCyZUt69+7Ns88+y5AhQ5gyZQoXXnghZsaECRNo2bIlZWVl9O/fn3fffZdu3bolvM78+fOZMmUKCxYsYPv27fTs2ZNevXoBcP7553PZZZcBcP311/OnP/2JK664gsGDB3Puuefyne98p8K1Nm/ezMiRI5k1axadOnXi4osv5r777uOqq64CoHXr1rz11lvce++9TJw4kQceeKDC+W3btmXGjBk0btyYpUuXMmzYMIqKinj22Wf5+9//zhtvvEFmZiZr164FYPjw4YwbN47zzjuPzZs3s2PHjn37rKVmuIdfuQUF8OST4VZPfn7YHjoUmjev8tTCwtAg/PHHYd6hCRNqv3F4+PBqvGeDBiHQDh3ClBXxysqgpGT3WseiRfCPf0D8ZJWZmbtuU5U/lz9WrIBf/xpeeAHatIGJE0ONIW5CzgNZKhNEO2BV3HYJcEKiA80sG8gFXtzDue0SnDcKGAXQIRXTrtaA8ttM5QniT3/6EwBPPPEEBQUFbN++nU8++YRFixZVmSBeeeUVzjvvvJ1Tbg8evGtJ7/fff5/rr7+eL774gq+++qrC7axElixZQm5uLp06dQJgxIgRTJo0aWeCOP/88wHo1asXTz/99G7na1rwA9SaNfDoo+E20uLFIRFcckloW8jL2+vpdaKLabyMjDDhWnZ2mAgvXlkZrFq1e/J4/32YNg0qT8nfpg3cfnuYWbWOJIZy6dJIPRR4yt3LqnOSuxcABQD5+fm+x4P38Es/lYYMGcLYsWN566232LhxI7169WLFihVMnDiRefPm0aJFC0aOHFnlNN97M3LkSKZOnUr37t15+OGHmTNnzn7FWz5leFXThcdPC75jxw596acz9zBSt6AA/vrX8Kv4xBPhwQfhwgur9WUW2RoIUcjICKPwcnLC9Nrxtm+vmDwyMuD7369ziaFcKpv0VwPt47azYmWJDKXi7aPqnJvWmjVrxmmnncall17KsGHDAPjyyy9p2rQphx56KP/973959tln93iNvn37MnXqVDZt2sT69et55plndu5bv349Rx55JNu2baMwblhp8+bNWb9+/W7XOvbYY1m5ciXFxcVAmJX11FNPTfrv0bTgB4BPPw2/aDt3DqN1p08PPWjefRdeey3UHKr5hVbrayCkq4MOgtxcOPPMMLNqHbqdlEgqE8Q8oKOZ5ZpZQ0ISmFb5IDPrTGiIfi2u+HngTDNrYWYtgDNjZQekYcOG8c477+xMEN27dycvL4/OnTtz0UUX0adPnz2e37NnT7773e/SvXt3zj77bL7xjW/s3HfzzTdzwgkn0KdPHzp37ryzfOjQodx+++3k5eVVWC+6cePGPPTQQ1xwwQV07dqVBg0aMHr06KT/Fk0LnqZ27Ag9Z7773TAW4JprQi+aRx6Bf/87TP7Wtes+X742F9SSNFJV63VNPIBzgA8JvZmui5WNBwbHHXMTcGuCcy8FimOPS/b2XunYi0mSo3+n/fDJJ+6/+Y370UeHHjQtW7pfdZX7woU1+jaRr8MsKUNUa1K7+3RgeqWyGypt31TFuQ8CD6YsOJED1Y4dMGNGaFuYNi3cFz/1VLj5Zjj//JRM9lbezhB1LyapXenSSC0ie7N6NTz0EDzwQOhG1Lp16L79gx/Ascem/O2r1cVU6oQ6nyDcHauJ6QEkJUINV3ZyD11SV64MfexXrgyPJUvCmgFlZaFP/223wZAhtbIusdRfdTpBNG7cmDVr1tCqVSsliTTk7qxZs6Z+dZV1DxPYlX/xxyeB8sdXX1U8p0WL0OXy6qvDuIVjjqnloKW+qtMJIisri5KSEkpLS6MORarQuHFjsrKyog6jZq1bt/sXf/z2l19WPP6QQ0LXyWOOCbWD3Nxd/fBzcmp+LiSRJNXpBHHwwQeTm5sbdRhS16xfn/jXf/n2F19UPL5p0/Cln5sbGpNzciomgcMOq5lZUkVqWJ1OECL7xR2eeSasAhafBGLzTO2Umbnry75Pn12vy5NAy5b7lQDSYQ4kqZ+UIEQSWbgQrrgiLA3ZuPGuL/1vfKPir//c3NCbKEU1gDo3B5IcUKyu9CLJz8/3oqKiqMOQA90XX4T5/P/wh9A2cMst4Rv5oGh+S+XkhKRQWXZ2qNCI7C8zm+/u+Yn2qQYhAmHw2cMPw7hx8NlnISncckuoHURIcyBJlNJo8VaRiLz5Jpx0EvzP/4Q5/ouK4I9/jDw5gOZAkmgpQUj99emnISmccEL4Sf7oo2GR+Z49o45spwkTdl+tMjMzlIukmhKE1D/btsHdd0OnTiEpXH11GKn8/e+nXXfT4cPDlEvZ2SG07OywrQZqqQ1qg5D6Zfbs0Dtp4cIwp//dd4d1E9KY5kCSqKgGIfXDxx+HVdROPx02bIC//Q2eey7tk4NIlJQgpG7bvDn0RurcOQx6+/Wvw8L03/pW2t1OEkk3usUkdVP5KOixY2H5cvj2t+F3vws38UUkKSmtQZjZQDNbYmbFZjauimMuNLNFZrbQzCbHlZeZ2YLYY7elSkWq9OGHcM45u6bDnjkTnnpKyUGkmlJWgzCzDGASMAAoAeaZ2TR3XxR3TEfgF0Afd//czNrGXWKTu/dIVXxSB61fH24n3XknNGkCd9wBY8bAwQdHHZnIASmVt5h6A8XuvhzAzKYAQ4BFccdcBkxy988B3P3TFMYjdZU7TJ4MP/85fPIJjBwJt94Khx8edWQiB7RU3mJqB6yK2y6JlcXrBHQys7lm9rqZDYzb19jMimLl30r0BmY2KnZMkdZ8qKcWLIC+feF734N27eC118KynEoOIvst6l5MBwEdgX7AMOB+Mzssti87NoHURcBdZrbbMlruXuDu+e6e36ZNm9qKWdLB2rXwox9Br17wwQdw//3wxhtw4ok19haFhWGyvAYNwnNhYY1dWuSAkMoEsRpoH7edFSuLVwJMc/dt7r4C+JCQMHD31bHn5cAcIC+FscqBoqwszJPUsWMYUvzjH4dG6R/8IHyT15DyabY/+ijcwSqfZltJQuqTVCaIeUBHM8s1s4bAUKByb6SphNoDZtaacMtpuZm1MLNGceV9qNh2IfXR3LlhPYbLL4euXeHtt+Gee8KazTXsuut2rcFQbuPGUC5SX6QsQbj7dmAM8DywGHjC3Rea2XgzGxw77HlgjZktAmYDP3f3NcDXgSIzeydWfmt87yepZz75JMyTdMopUFoKU6aEKTO6dk3ZW2qabREtGCTpbOvWMFfS+PHh9dVXwy9/GdZ4TjEt1CP1xZ4WDIq6kVoksVdfhW7d4JproF+/MLnehAm1khxA02yLgBKEpKM5c+CMM8K03P/8Z5gy42tfq9UQNM22iOZiknTz0kswaBDk5oZ2hrZt935OimiabanvVIOQ9PHyy2EOpexsePHFSJODiChBSLp45ZWQHDp0CMlBI6FFIqcEIdH717/g7LOhfftwW+mII6KOSERQgpCozZ0bkkNWVqg5KDmIpA0lCInOq6/CwIFw1FGh5nDkkVFHJCJxlCAkGq+9FpLDkUcqOYikKSUIqX2vvw5nnRUaomfPDjUIEUk7ShBSu954IySHtm1DcmhXeYkQEUkXShBSe958E848E9q0CaOls7KijkhE9kAJQmrHvHkhObRuHWoOSg4iaU8JQlKvqAgGDICWLUNyaN9+7+eISOSUICS15s/flRzmzAkjpfdCS32KpIeUJggzG2hmS8ys2MzGVXHMhWa2yMwWmtnkuPIRZrY09hiRyjglRd56KySHww4LNYckk4OW+hRJDylbMMjMMghrTA8grD09DxgWvzKcmXUEngBOd/fPzaytu39qZi2BIiAfcGA+0MvdP6/q/bRgUJp5660wZfchh4SaQ05OUqdpoR6R2hXVgkG9gWJ3X+7uW4EpwJBKx1wGTCr/4nf3T2PlZwEz3H1tbN8MYGAKY5Wa9PbbITk0b16t5ABa6lMknaQyQbQDVsVtl8TK4nUCOpnZXDN73cwGVuNczGyUmRWZWVFpaWkNhi77bMGCkByaNat2coCq70IlcXdKRGpY1I3UBwEdgX7AMOB+Mzss2ZPdvcDd8909v02bNikKUZL2zjvQv39YFnTOnLDoTzVpqU+R9JHKBLEaiO/PmBUri1cCTHP3be6+gtBm0THJcyWdvPtuSA6ZmaFB+uij9+kyWupTJH2kspH6IMIXfn/Cl/s84CJ3Xxh3zEBCw/UIM2sNvA30YFfDdM/YoW8RGqnXVvV+aqSO0HvvwemnQ6NGoeZQy+tHi8i+21MjdcrWpHb37WY2BngeyAAedPeFZjYeKHL3abF9Z5rZIqAM+Lm7r4kFfTMhqQCM31NykAi9/35IDg0bKjmI1DEpq0HUNtUgIrBwIZx2Ghx8cEgOHTtGHZGIVFNU3VylLlu0KNQcDjootDkoOYjUOUoQUn2LFoWaQ0ZGSA6dOkUdkYikgBKEVM/ixaHm0KBBWEP62GOjjkhEUkQJQpL3wQeh5gCh5tC5c7TxiEhKpawXk9QxS5aE5OAeGqSVHETqvL3WIMzs/5mZahr12YcfhuSwY0eoOXz961FHJCK1IJkv/u8CS83sNjPTz8b6ZunSkBy2bw9tDscdF3VEIlJL9pog3P17QB6wDHjYzF6LTZLXPOXRSbSWLoV+/WDbtpAcjj8+6ohEpBYldevI3b8EniJM2X0kcB7wlpldkcLYJErFxaHmsHVrSA5dukQdkYjUsmTaIAab2d+AOcDBQG93PxvoDvwsteFJJJYtC8lh82YlB5F6LJleTN8G7nT3l+ML3X2jmf1PasKSyCxcCGefDZs2heTQtWvUEYlIRJK5xXQT8Gb5hpk1MbMcAHeflZKopPZt2gS/+hXk5YXXs2ZBt25RRyUiEUomQTwJ7IjbLouVSV0xc2ZIBrfcAkOHhlpE9+5RRyUiEUsmQRwUW1MagNjrhqkLSWpNaSl8//swYEDYnjEDHn0U2raNNi4RSQvJJIhSMxtcvmFmQ4DPUheSpJw7PPhgGA39+ONw/fVhRbgzzog6MhFJI8k0Uo8GCs3sD4ABq4CLUxqVpM4HH8APfwgvvwynnAL/938a/CYiCSUzUG6Zu58IHAd83d1PdvfiZC5uZgPNbImZFZvZuAT7R5pZqZktiD1+ELevLK58WnX+KElg82a48cbQ1vDuu3D//fDSS0oOIlKlpCbrM7NBwPFAYzMDwN3H7+WcDGASMAAoAeaZ2TR3X1Tp0MfdfUyCS2xy9x7JxCd7MXs2jB4d5lQaPhx+9zs4/PCooxKRNJfMQLk/EuZjuoJwi+kCIDuJa/cGit19eaxhewowZD9iler67DMYOTKs31BWBi+8AI89puQgIklJppH6ZHe/GPjc3X8NnAQks4RYO0J7RbmSWFll3zazd83sKTNrH1fe2MyKzOx1M/tWojeIzQlVZGZFpaWlSYRUT7jDww+HRujCQvjlL+G993b1VqpCYSHk5IS1gHJywraI1F/JJIjNseeNZnYUsI0wH1NNeAbIcfduwAzgkbh92bGFtC8C7jKzYyqf7O4F7p7v7vlt2rSpoZAOcEuWhBrDJZeE1d4WLIAJE6BJkz2eVlgIo0bBRx+F/PLRR2FbSUKk/komQTxjZocBtwNvASuByUmctxqIrxFkxcp2cvc17r4ltvkA0Ctu3+rY83LCPFB5Sbxn/bVlC4wfHxqhFywIvZNeeSXpGVivuw42bqxYtnFjKBeR+mmPjdSxhYJmufsXwF/N7B9AY3dfl8S15wEdzSyXkBiGEmoD8dc/0t0/iW0OBhbHylsAG919i5m1BvoAt1Xj76pfXnopdF1dsgSGDYM77oAjjqjWJT7+uHrlIlL37bEG4e47CD2Ryre3JJkccPftwBjgecIX/xPuvtDMxscNvLvSzBaa2TvAlcDIWPnXgaJY+Wzg1gS9n2TNGrj00rBmw9at8NxzMHlytZMDQIcO1SsXkbrP3H3PB5hNBF4Dnva9HRyh/Px8LyoqijqM2uEeeiP99KfwxRdw9dVhor3MzH2+ZHkbRPxtpsxMKCgIPWNFpG4ys/mx9t7dJNMG8UPC5HxbzOxLM1tvZl/WaISSvKVLQ2+kiy+Gr30N3noLfvOb/UoOEJJAQQFkZ4NZeFZyEKnf9jpQzt21tGg62LoVbrstzLjauDHcd1/4yd8gqUUBkzJ8uBKCiOyy1wRhZn0TlVdeQEhS6JVXQiP04sVw4YVw111wZE31NBYRSSyZqTZ+Hve6MWGE9Hzg9JREJLusXQvXXgsPPBDu+fzzn3DOOVFHJSL1RDK3mP5f/HZstPNdKYtIQiP05MkwdmxIEtdcAzfcAE2bRh2ZiNQjSU3WV0kJoRuqpMKyZXD55WHxnhNOCM9a3U1EIpBMG8TvgfLurQ2AHoQR1VKTysrgt7+Fm2+Ghg1h0qTQ7pCREXVkIlJPJVODiB9csB34i7vPTVE89dOOHfCDH4QJ9i64IDRCH3VU1FGJSD2XTIJ4Ctjs7mUQ1nkws0x337iX8yQZ7vCTn4TkcNNNYVEfEZE0kEwn+llA/FSgTYCZqQmnHrr+evjDH+BnPwsN0SIiaSKZBNHY3b8q34i93r9huxLceiv87//CZZfB7beHIcwiImkimQSxwcx6lm+YWS9gU+pCqicmTYJf/AIuuiiMilZyEJE0k0wbxFXAk2b2b8KSo0cQliCVffXIIzBmDAweHNoe1FNJRNJQMgPl5plZZ+DYWNESd9+W2rDqsL/+NUzR3b8/PP44HHxw1BGJiCS011tMZvZjoKm7v+/u7wPNzOxHqQ+tDnr++bCgzwknwNSpYdI9EZE0lUwbxGWxFeUAcPfPgcuSubiZDTSzJWZWbGbjEuwfaWalZrYg9vhB3L4RZrY09hiRzPultZdfhvPOC0uATp8OzZpFHZGIyB4l0waRYWZWvliQmWUADfd2Uuy4SUUYJo8AAA6BSURBVMAAwvQc88xsWoKV4R539zGVzm0J3AjkE0Zxz4+d+3kS8aafoiI499ww4d4LL8Bhh0UdkYjIXiVTg3gOeNzM+ptZf+AvwLNJnNcbKHb35e6+FZgCDEkyrrOAGe6+NpYUZgADkzw3vbz/Ppx1FrRqFeZVatMm6ohERJKSTIK4FngRGB17vEfFgXNVaQesitsuiZVV9m0ze9fMnorNFJv0uWY2ysyKzKyotLQ0iZBqWXFxWP2tUSOYOROysqKOSEQkaXtNEO6+A3gDWEmoFZwOLK6h938GyHH3boRawiPVOdndC9w9393z26TbL/NVq+CMM2DbtpAcjjkm6ohERKqlyjYIM+sEDIs9PgMeB3D305K89mqgfdx2VqxsJ3dfE7f5AHBb3Ln9Kp07J8n3jd6nn4bk8Pnn8OKLcNxxUUckIlJte6pBfECoLZzr7qe4+++Bsmpcex7Q0cxyzawhMBSYFn+AmcWvmzmYXTWT54EzzayFmbUAzoyVpb/PP4czzww1iH/+E3r1ijoiEZF9sqdeTOcTvtRnm9lzhEbmpOeDcPftZjaG8MWeATzo7gvNbDxQ5O7TgCvNbDBhGvG1wMjYuWvN7GZCkgEY7+5rq/enRWD9+rAk6OLF8MwzcMopUUckIrLPLNZ7teoDzJoSeh8NI9QoHgX+5u4vpD685OXn53tRUdHeD0yVzZtDcnj5ZXjyyTDmQUQkzZnZfHfPT7QvmUbqDe4+ObY2dRbwNqFnk5Tbti0s9DN7dphbqZrJobAQcnKgQYPwXFiYiiBFRKqnWmtSx8YkFMQeAmGp0Isvhn/8A+69F773vWqdXlgIo0bBxtjySx99FLYBhg+v4VhFRKohmXEQUhV3GD0apkwJ60lffnm1L3HddbuSQ7mNG0O5iEiUlCD2lTv89KfwwANhVbhrrtmny3z8cfXKRURqixLEvvr1r+Guu+DKK2H8+H2+TIcO1SsXEaktShD74ne/Cwnikkvgzjv3azW4CRMgs9ICrpmZoVxEJEpKENVVUABXXx16Ld1/f+h6tB+GDw+XzM4OeSY7O2yrgVpEolatXkz13uTJoVH6nHPgscdqbKnQ4cOVEEQk/agGkay//z10Z+3bF556ChrudUkMEZEDmhJEMmbOhAsvDPMqPfMMNElmtnMRkQObEsTevPoqDBkCxx4Lzz4LzZtHHZGISK1QgtiTt98O7Q3t2oWlQlu2jDoiEZFaowRRlcWLw7TdhxwSbjEdcUTUEYmI1ColiERWrAhLhWZkwKxZGrUmIvWSurlWtno19O8fJkR66SXo2DHqiEREIqEEEe+zz0LNobQ01By6do06IhGRyKT0FpOZDTSzJWZWbGbj9nDct83MzSw/tp1jZpvMbEHs8cdUxgnAunVw1lnh9tI//gG9e6f8LUVE0lnKahBmlgFMAgYAJcA8M5vm7osqHdcc+AnwRqVLLHP3HqmKr4ING2DQIHjvvTAg7tRTa+VtRUTSWSprEL2BYndf7u5bCWtaD0lw3M3Ab4HNKYylalu2hBXgXnstrN5z9tmRhCEikm5SmSDaAavitktiZTuZWU+gvbv/M8H5uWb2tpm9ZGbfTPQGZjbKzIrMrKi0tHTfovz3v2HRorCuwwUX7Ns1RETqoMgaqc2sAXAHMDLB7k+ADu6+xsx6AVPN7Hh3/zL+IHffufxpfn6+71MgubnwwQfQrNk+nS4iUlelsgaxGmgft50VKyvXHOgCzDGzlcCJwDQzy3f3Le6+BsDd5wPLgE4pi1TJQURkN6lMEPOAjmaWa2YNgaHAtPKd7r7O3Vu7e4675wCvA4PdvcjM2sQauTGzo4GOwPIUxioiIpWk7BaTu283szHA80AG8KC7LzSz8UCRu0/bw+l9gfFmtg3YAYx297WpilVERHZn7vt26z7d5Ofne1FRUdRhiIgcUMxsvrvnJ9qnuZhERCQhJQgREUlICUJERBJSghARkYSUIEREJCElCBERSUgJQkREElKCEBGRhJQgREQkISUIERFJSAlCREQSUoIQEZGElCBERCQhJQgREUlICUJERBJKaYIws4FmtsTMis1s3B6O+7aZuZnlx5X9InbeEjM7K5VxiojI7lK2olxsydBJwACgBJhnZtPcfVGl45oDPwHeiCs7jrBE6fHAUcBMM+vk7mWpildERCpKZQ2iN1Ds7svdfSswBRiS4Libgd8Cm+PKhgBT3H2Lu68AimPXExGRWpLKBNEOWBW3XRIr28nMegLt3f2f1T03dv4oMysys6LS0tKaiVpERIAIG6nNrAFwB/Czfb2Guxe4e76757dp06bmghMRkdS1QQCrgfZx21mxsnLNgS7AHDMDOAKYZmaDkzhXRERSLJU1iHlARzPLNbOGhEbnaeU73X2du7d29xx3zwFeBwa7e1HsuKFm1sjMcoGOwJspjFVERCpJWQ3C3beb2RjgeSADeNDdF5rZeKDI3aft4dyFZvYEsAjYDvxYPZhERGqXuXvUMdSI/Px8LyoqijoMEZEDipnNd/f8RPs0klpERBJSghARkYSUIEREJCElCBERSUgJQkREElKCEBGRhJQgREQkISUIERFJSAlCREQSUoIQEZGElCBERCQhJQgREUlICUJERBJSghARkYSUIEREJCElCBERSSilCcLMBprZEjMrNrNxCfaPNrP3zGyBmf3LzI6LleeY2aZY+QIz+2Mq4xQRkd2lbMlRM8sAJgEDgBJgnplNc/dFcYdNdvc/xo4fDNwBDIztW+buPVIVn4iI7FkqaxC9gWJ3X+7uW4EpwJD4A9z9y7jNpkDdWP9URKQOSGWCaAesitsuiZVVYGY/NrNlwG3AlXG7cs3sbTN7ycy+megNzGyUmRWZWVFpaWlNxi4iUu9F3kjt7pPc/RjgWuD6WPEnQAd3zwN+Ckw2s0MSnFvg7vnunt+mTZvaC1pEpB5IZYJYDbSP286KlVVlCvAtAHff4u5rYq/nA8uATimKU0REEkhlgpgHdDSzXDNrCAwFpsUfYGYd4zYHAUtj5W1ijdyY2dFAR2B5CmMVEZFKUpYg3H07MAZ4HlgMPOHuC81sfKzHEsAYM1toZgsIt5JGxMr7Au/Gyp8CRrv72lTEWVgIOTnQoEF4LixMxbuIiBx4zL1udBzKz8/3oqKiap1TWAijRsHGjbvKMjOhoACGD6/hAEVE0pCZzXf3/ET7Im+kjtJ111VMDhC2r7sumnhERNJJvU4QH39cvXIRkfqkXieIDh2qVy4iUp/U6wQxYUJoc4iXmRnKRUTqu3qdIIYPDw3S2dlgFp7VQC0iEqRssr4DxfDhSggiIonU6xqEiIhUTQlCREQSUoIQEZGElCBERCQhJQgREUmozszFZGalwEf7cYnWwGc1FM6BTp9FRfo8KtLnsUtd+Cyy3T3hgjp1JkHsLzMrqmrCqvpGn0VF+jwq0uexS13/LHSLSUREElKCEBGRhJQgdimIOoA0os+iIn0eFenz2KVOfxZqgxARkYRUgxARkYSUIEREJKF6nyDMbKCZLTGzYjMbF3U8UTKz9mY228wWmdlCM/tJ1DFFzcwyzOxtM/tH1LFEzcwOM7OnzOwDM1tsZidFHVOUzGxs7P+T983sL2bWOOqYalq9ThBmlgFMAs4GjgOGmdlx0UYVqe3Az9z9OOBE4Mf1/PMA+AmwOOog0sTdwHPu3hnoTj3+XMysHXAlkO/uXYAMYGi0UdW8ep0ggN5Asbsvd/etwBRgSMQxRcbdP3H3t2Kv1xO+ANpFG1V0zCwLGAQ8EHUsUTOzQ4G+wJ8A3H2ru38RbVSROwhoYmYHAZnAvyOOp8bV9wTRDlgVt11CPf5CjGdmOUAe8Ea0kUTqLuAaYEfUgaSBXKAUeCh2y+0BM2sadVBRcffVwETgY+ATYJ27vxBtVDWvvicIScDMmgF/Ba5y9y+jjicKZnYu8Km7z486ljRxENATuM/d84ANQL1tszOzFoS7DbnAUUBTM/tetFHVvPqeIFYD7eO2s2Jl9ZaZHUxIDoXu/nTU8USoDzDYzFYSbj2ebmaPRRtSpEqAEncvr1E+RUgY9dUZwAp3L3X3bcDTwMkRx1Tj6nuCmAd0NLNcM2tIaGSaFnFMkTEzI9xjXuzud0QdT5Tc/RfunuXuOYT/Ll509zr3CzFZ7v4fYJWZHRsr6g8sijCkqH0MnGhmmbH/b/pTBxvtD4o6gCi5+3YzGwM8T+iF8KC7L4w4rCj1Ab4PvGdmC2Jlv3T36RHGJOnjCqAw9mNqOXBJxPFExt3fMLOngLcIvf/epg5Ou6GpNkREJKH6fotJRESqoAQhIiIJKUGIiEhCShAiIpKQEoSIiCSkBCGyF2ZWZmYL4h41NoLYzHLM7P2aup5ITarX4yBEkrTJ3XtEHYRIbVMNQmQfmdlKM7vNzN4zszfN7Gux8hwze9HM3jWzWWbWIVZ+uJn9zczeiT3Kp2bIMLP7Y2sLvGBmTWLHXxlbm+NdM5sS0Z8p9ZgShMjeNal0i+m7cfvWuXtX4A+E2V8Bfg884u7dgELgnlj5PcBL7t6dMI9R+aj9jsAkdz8e+AL4dqx8HJAXu87oVP1xIlXRSGqRvTCzr9y9WYLylcDp7r48Nsnhf9y9lZl9Bhzp7tti5Z+4e2szKwWy3H1L3DVygBnu3jG2fS1wsLvfYmbPAV8BU4Gp7v5Viv9UkQpUgxDZP17F6+rYEve6jF1tg4MIKx72BObFFqYRqTVKECL757txz6/FXr/KruUnhwOvxF7PAi6HnWtdH1rVRc2sAdDe3WcD1wKHArvVYkRSSb9IRPauSdzsthDWZS7v6trCzN4l1AKGxcquIKy89nPCKmzls57+BCgws/8h1BQuJ6xGlkgG8FgsiRhwj5b4lNqmNgiRfRRrg8h398+ijkUkFXSLSUREElINQkREElINQkREElKCEBGRhJQgREQkISUIERFJSAlCREQS+v8bkPyDL/zAAQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sM7dqi5dxco"
      },
      "source": [
        "## 3. Train (again) and evaluate the model\n",
        "\n",
        "- To this end, you have found the \"best\" hyper-parameters. \n",
        "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
        "- Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyvkbzx8dxcp"
      },
      "source": [
        "### 3.1. Train the model on the entire training set\n",
        "\n",
        "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw3C5iQTdxcp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6985e1e-31c0-46d9-f2bd-3901d9dc29ec"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3),kernel_regularizer=regularizers.l2(l=0.1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), activation='relu', kernel_regularizer = regularizers.l2(l=0.1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.20))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=regularizers.l2(l=0.1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), activation='relu', kernel_regularizer = regularizers.l2(l=0.1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.30))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 15, 15, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 13, 13, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 13, 13, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 196,618\n",
            "Trainable params: 196,298\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5hcCAROdxcq"
      },
      "source": [
        "#<Train your model on the entire training set (50K samples)>\n",
        "#<Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
        "#<Do NOT use the validation_data option (because now you do not have validation data)>\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "learning_rate = 0.0001 # to be tuned!\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEvzuYitcsKI",
        "outputId": "384b13bd-e549-4d92-8a34-1c9a907e9edb"
      },
      "source": [
        "history = model.fit(x_train, y_train_vec, batch_size=32, epochs=10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 10s 5ms/step - loss: 11.6983 - acc: 0.2847\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 4.3631 - acc: 0.4924\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 2.5896 - acc: 0.5687\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8936 - acc: 0.6248\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5247 - acc: 0.6677\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3008 - acc: 0.6986\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1514 - acc: 0.7232\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0623 - acc: 0.7383\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9871 - acc: 0.7514\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9297 - acc: 0.7630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpnek1E3dxcq"
      },
      "source": [
        "### 3.2. Evaluate the model on the test set\n",
        "\n",
        "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCLBB-o2dxcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f2239a-71ac-4958-ac62-ed7fd7ec8c0c"
      },
      "source": [
        "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9564 - acc: 0.7551\n",
            "loss = 0.9563670754432678\n",
            "accuracy = 0.7551000118255615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhLw8XISdxcq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}